{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ================ TWITTER ======================\n",
    "\n",
    "def get_user_tweets(api, username, count=200):\n",
    "    tweets = api.user_timeline(username, count=count)\n",
    "    texts = [tweet.text for tweet in tweets]\n",
    "    return texts#twitter authentication\n",
    "\n",
    "def get_tweets():\n",
    "    #twitter authentication\n",
    "    CONSUMER_KEY        =  os.getenv('api-key')\n",
    "    CONSUMER_SECRET     =  os.getenv('api-secret-key')\n",
    "    ACCESS_TOKEN        =  os.getenv('access-token')\n",
    "    ACCESS_TOKEN_SECRET =  os.getenv('access-secret-token')\n",
    "    AUTH = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    AUTH.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "    api = tweepy.API(AUTH)    \n",
    "    return(get_user_tweets(api, username),api.get_user(username).name)\n",
    "\n",
    "username=\"LaRagazzaTurca_\"\n",
    "all_tweets = get_tweets()[0]\n",
    "name = get_tweets()[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Mention: 69\n",
      "Total Retweet: 69\n",
      "Total Tweet: 60\n"
     ]
    }
   ],
   "source": [
    "mn=0\n",
    "rt=0\n",
    "tw=0\n",
    "\n",
    "mentions=[]\n",
    "retweets=[]\n",
    "tweets=[]\n",
    "\n",
    "for m in all_tweets:\n",
    "    if m[0] == \"@\":\n",
    "        mn = mn + 1\n",
    "        mentions.append(m)\n",
    "    elif m[0:2] == \"RT\":\n",
    "        rt = rt + 1\n",
    "        retweets.append(m)\n",
    "    else:\n",
    "        tw = tw + 1\n",
    "        tweets.append(m)\n",
    "        \n",
    "print(\"Total Mention:\",mn)\n",
    "print(\"Total Retweet:\",rt)\n",
    "print(\"Total Tweet:\",tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Retweets  \\\n",
      "0  RT @sibirbil: ArkadaÅŸlar ilginiz iÃ§in Ã§ok teÅŸe...   \n",
      "1  RT @munferit1aslan: Bir Ã¶ÄŸretmenler gÃ¼nÃ¼nde Ã¼z...   \n",
      "2  RT @bbcturkce: #RabiaNazaNeOldu: 3 Senaryo \\n\\...   \n",
      "3  RT @metcihan: MÃ¼rsel KÃ¼Ã§Ã¼kal'Ä±n sÃ¼rÃ¼nme hareke...   \n",
      "4  RT @BarisAkademik: BarÄ±ÅŸ akademisyenlerinin gÃ¶...   \n",
      "\n",
      "                                              Tweets  \\\n",
      "0  #24KasimOgretmenlerGunuKutluOlsun https://t.co...   \n",
      "1  GÃ¶lcÃ¼k'ten Berlin Teknik'e uzanan bir baÅŸarÄ± h...   \n",
      "2  \"Bizim zamanÄ±mÄ±zda da bÃ¶yleydi\" lafÄ± meÄŸer Ã§oo...   \n",
      "3  BugÃ¼n #FountainPenDay. AkÅŸamÄ±mÄ± harika kalem, ...   \n",
      "4  #AdanaLezzetFestivali 4, 5, 6 Ekim'de Adana Me...   \n",
      "\n",
      "                                            Mentions  \n",
      "0  @bilimhatunu DÃ¼zeltmek kaba deÄŸil kesinlikle. ...  \n",
      "1  @pyolum Once ben de @pyolum gibi bir danÄ±ÅŸman ...  \n",
      "2                              @sibirbil kesinlikle!  \n",
      "3  @Bogazici_CmpE Web sitesinden Ã¶nce Ã¶ÄŸrencimizi...  \n",
      "4  @Bogazici_CmpE .@Bogazici_CmpE aile fotoÄŸrafÄ±m...  \n"
     ]
    }
   ],
   "source": [
    "df_retweets = pd.DataFrame({'retweets': retweets})\n",
    "df_tweets = pd.DataFrame({'tweets': tweets})\n",
    "df_mentions = pd.DataFrame({'mentions': mentions})\n",
    "\n",
    "df_all=pd.concat([df_retweets,df_tweets,df_mentions],ignore_index=True, axis=1)\n",
    "df_all.columns = [ 'Retweets','Tweets', 'Mentions']\n",
    "\n",
    "print(df_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#24kasimogretmenlergunukutluolsun https://t.co/iszalqdcwg\n",
      "gÃ¶lcÃ¼k'ten berlin teknik'e uzanan bir baÅŸarÄ± hikayesi #begÃ¼mdemir iÌ‡yi ki yolumuz trento'da kesiÅŸmiÅŸ &lt;3 \n",
      "https://t.co/tdjrhxdcrk\n",
      "\"bizim zamanÄ±mÄ±zda da bÃ¶yleydi\" lafÄ± meÄŸer Ã§ook geriye gidiyormuÅŸ. rt @cwjones89: academics complaining that departâ€¦ https://t.co/re1yedsptt\n",
      "bugÃ¼n #fountainpenday. akÅŸamÄ±mÄ± harika kalem, mÃ¼rekkep ve yazÄ± fotoÄŸraflarÄ±na bakarak geÃ§iriyorumðŸ˜ evdeki bebekleriâ€¦ https://t.co/7uwbvliqt8\n",
      "#adanalezzetfestivali 4, 5, 6 ekim'de adana merkez park'taymÄ±ÅŸ. festival programÄ±nda festival mangalÄ±nÄ±n yakÄ±lmasÄ±â€¦ https://t.co/ep0dz4d9as\n",
      "avrupa ikinciliÄŸi iÃ§in tebrikler #fileninsultanlarÄ±\n",
      "finaldeyiz ðŸ‡¹ðŸ‡·ðŸ‡¹ðŸ‡·ðŸ‡¹ðŸ‡·ðŸ’ƒðŸ»ðŸ’ƒðŸ»ðŸ’ƒðŸ»  #simgeakÃ¶z #edaerdem ðŸ’œ #fileninsultanlarÄ±\n",
      "#fileninsultanlarÄ± hollanda'yÄ± 3-0 skorla devirdi ðŸ’ªðŸ‡¹ðŸ‡·ðŸ‡¹ðŸ‡·ðŸ‡¹ðŸ‡· yarÄ± final cumartesi polonya veya almanya ile\n",
      "#sulecetiÌ‡cinadalet rt @suleicinadalet: #sulecetiÌ‡cinadalet https://t.co/ghlyl6ykvy\n",
      "#unutmadimaklÄ±mda https://t.co/tpllo6knzc\n",
      "bugÃ¼n her ÅŸey Ã§ok gÃ¼zel oldu, ilerde de #herÅŸeyÃ§okgÃ¼zelolacak ðŸ‡¹ðŸ‡·ðŸ‡¹ðŸ‡·ðŸ‡¹ðŸ‡·\n",
      ".@bogazici_cmpe bugÃ¼n bitirme projesi sunumlarÄ± ile cÄ±vÄ±l cÄ±vÄ±l! https://t.co/rit4ezwp41\n",
      ".@inzvaspace #ai project showcase etkinliginde pek cok lisansÃ¼stÃ¼ ve lisans @bogazici_cmpe ogrencisi de sahte akadeâ€¦ https://t.co/cfmrmrinux\n",
      ".@buenso organizasyonu #icames19 icin levent akÄ±n hocamla jÃ¼ri Ã¼yeliÄŸi hatÄ±ramÄ±z :) farklÄ± Ã¼lkelerden mÃ¼hendislik Ã¶â€¦ https://t.co/ktighmuvwj\n",
      "doktora tezini baÅŸarÄ±yla sunan @bariskurt danÄ±ÅŸmanÄ± taylan cemgil ile @bogazici_cmpe https://t.co/a6mbshvgdz\n",
      ". @bariskurt doktora tezini sunmak Ã¼zere! https://t.co/zfjshcenb1\n",
      ".@bogazici_cmpe'den @_emre_ugur_ #esnekuretim iÃ§in #robotik anlatÄ±yor. @buindustry4zero https://t.co/2pjvbwkrje\n",
      "#kitapchallenge'a kaldÄ±ÄŸÄ±m yerden devam edeyim, 6. gÃ¼n #catch22 #josephheller https://t.co/yo7ayefmcz\n",
      "bu da baÅŸka tÃ¼r #kitapchallenge. yurt dÄ±ÅŸÄ±nda bÃ¼yÃ¼mÃ¼ÅŸ, tÃ¼rkÃ§eleri Ã§ok akÄ±cÄ± olmayan 12 -13 yaÅŸÄ±nda Ã§ocuklar iÃ§in tÃ¼â€¦ https://t.co/gya1w4aalr\n",
      "#kitapchallenge 5. gÃ¼n #jacklondon'dan #martineden \n",
      "\n",
      "@skocacan 7 gÃ¼n sevdiÄŸin kitaplarÄ±n kapaklarÄ±nÄ± paylaÅŸÄ±r mÄ±sÄ±n? https://t.co/q8vybpdmnh\n",
      "#kitapchallenge 4. gÃ¼n, @svlchsn i davet ediyorum :) kitap chimamanda ngozi adichie'den #americanah https://t.co/4cdtkq6i4i\n",
      "#kitapchallenge 3. gÃ¼n: gÃ¼nÃ¼n kitabÄ± tanpÄ±nar'dan huzur. katÄ±lmak isterse @metdos u davet ediyorum. https://t.co/wx1cc2cpvh\n",
      ".@say_cem hocamÄ±n daveti de geldi. #kitapchallenge 2. gÃ¼n. @gundogdudidem sen de gelsene https://t.co/1gqiepbxtv\n",
      "#kitapchallenge 1. gÃ¼n, @nkokciyan davet etti. @zkiziltoprak var mÄ±sÄ±n? https://t.co/eqe1lbazrh\n",
      "iÌ‡lk baskÄ±ya yetiÅŸemedim, 2. baskÄ±dan bir kendime bir de anne babamÄ±n kÃ¶yÃ¼ndeki ilkokula hediyelik kaptÄ±m. @say_cemâ€¦ https://t.co/pmbvylxzfi\n",
      "japon imparatorunun balÄ±k bilimi uzmanÄ± olup yayÄ±n Ã§Ä±kardÄ±ÄŸÄ±nÄ± yeni Ã¶ÄŸrendim. soyadÄ± yok, adres imparatorluk sarayÄ±â€¦ https://t.co/cvok33izyy\n",
      "noordwijk'teki avrupa uzay ajansi'nda mutlu bir ben :) bazÄ± verileri herkese acik, bir kÄ±sÄ±m veriler ajansa Ã¼ye olmâ€¦ https://t.co/dj2ouuhz4z\n",
      "bir arkadasim mobil/web uygulamalar alaninda staj yapabilecegi bir sirket ariyor. ilgilenen biri cikar mi acaba?\n",
      "yazÄ±lÄ±m mÃ¼hendisliÄŸi ile ilgilenen herkes bugÃ¼nkÃ¼ icse davetli konuÅŸmacÄ±larÄ±n dinlemeli. rt @aydemirfb: highly recoâ€¦ https://t.co/uvj3hb4lju\n",
      "bilgi universitesi'nden ayhan kaya islam-ophob-ism projesiyle turkiye'den tek isim. tebrikler! https://t.co/n13dol5pyz\n",
      "#remotesensing ve #earthobservation uzerinde calisiyorsaniz harika bir firsat https://t.co/x5mpsa5k7k\n",
      "#hollanda'da yasamanin bir de bu yuzu var: https://t.co/5shyyvmepe\n",
      "neyse bugun bisikleti almamistim https://t.co/cn2persnar\n",
      "turkiye expatlerin kendini guvende hissettigi ulkeler listesinin sonlarinda. https://t.co/8kkn45evjs\n",
      "yazÄ±lÄ±m mÃ¼hendisliÄŸi iÃ§in ulusal bir e-posta grubu var mÄ± acaba?\n",
      "diploma denkligimi almaya calisiyorum, butun asamalari tamamlayinca detayli yazarim. epey mesai istiyor :/\n",
      "konsoloslugun yeni binasi guzelmis. personel her zamanki gibi cok yardimci.\n",
      "milano baskonsoloslugundayim. gunun populer konulari askerlik tecil ve kadinlarin evlilik sonrasi soyadi degisikligi\n",
      "su teyze gibi olmak istiyorum o yasa gelebilirsem https://t.co/dm0yjw8g9k\n",
      "hollanda expatler icin en iyi 13. ulke secilmis. turkiye 56, italya 60. sirada. tek ben degilmisim sikayet eden :)\n",
      "https://t.co/jlncsgg7ol\n",
      "#refsq18 e katilmayi dusunmez miydiniz? https://t.co/bz3mdjzob5\n",
      "sunumlarinizi tesekkur veya soru slayti yerine ozet slaytiyla bitirin diyor, iyi fikir! https://t.co/tedm3usw4s\n",
      ".@svlchsn adÄ±m adÄ±m ile iÌ‡yilik peÅŸinde koÅŸuyor, ben de destek oldum. kampanya sayfasi: https://t.co/vuiriu1tpg #iyilikpesindekos\n",
      "bu yÄ±l instagram hesabÄ±m ÅŸarkÄ±lÄ± tÃ¼rkÃ¼lÃ¼ kutlamalarla doldu taÅŸtÄ±, ne gÃ¼zel. hepimizin cumhuriyet bayramÄ± kutlu olsun! ðŸ‡¹ðŸ‡·ðŸ‡¹ðŸ‡·ðŸ‡¹ðŸ‡·\n",
      ":( https://t.co/sbpaczd3dt\n",
      "tweet ve kullanici adi uyumu :) https://t.co/suks3jxacd\n",
      "#bigearth projesi #uzaktanalgilama #remotesensing alaninda 2 #postdoc ariyor. https://t.co/mpgwixwxm8\n",
      ".@wc_refsq  25 eylul ozet, 2 ekim bildiri gonderimi icin son gun! konferans 19-22 mart arasi utrecht'te! https://t.co/2d2n9ql8jy\n",
      "#utrecht newcomer's guide: https://t.co/l4whxoqjhi\n",
      "3'u kadin 4 turk arastirmacinin projeleri kabul edilmis, 2 proje turkiye'de, 1'i italya'da 1'i ispanya'da yurutulecâ€¦ https://t.co/2jxqxfpnoi\n",
      "cevreniz genisledikce ictenlikle sohbet edebileceginiz insan sayisi arttigindan sosyal etkinlikler daha cekilir oluyor.\n",
      "konferanslarda havadan sudan konusma rehberi https://t.co/gotbwploip\n",
      "ilk defa ben dinleyiciler arasidayken konusmaci daha once yaptigim bir ise atifta bulundu. hayat bana guzel!\n",
      "bazen kendimi boyle yakaliyorum, farkindalik onemli... https://t.co/hgj3x1yjkd\n",
      "#heavymetal sevenler icin: bir arkadasin 5026 albumu degerlendirdigi site https://t.co/xh7brq669n\n",
      "#kitapagacihollanda olarak bu pazar @mariolevi_ den iÌ‡Ã§imdeki iÌ‡stanbul fotoÄŸraflarÄ±'ni tartisacagiz.   katilmak isteyenleri bekleriz.\n",
      "turkiye'deki haber sitelerine de bu ozellik gelsin lutfen. https://t.co/kkbrjussdf\n",
      "got'un yeni sezonunda gordugumuz zincirlenmis kitaplara dair bir yazi  ve video https://t.co/r6xtgegpyd\n",
      "2 yil once milano'da gormustum bu yesil apartmani. fotograf bu sabah tekrar karsima cikti. https://t.co/q2iggghyau\n",
      "yardimci docent begum demir (uni. of trento) big earth adli projesiyle erc starting grant  almaya hak kazandi. \n",
      "#turkbilimdiasporasi\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "df_all= df_all.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "\n",
    "for m in df_all['Tweets']:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "disa_donuk=['!',\"konser\",\"arkadaÅŸ\",\"oley\",'hadi',\"hey\",'tatlÄ±m','canÄ±m','kuzum','bebek','bebeÄŸim','mÃ¼kemmel','ÅŸaka',\n",
    "            'selam','kutlarÄ±m','sosyal']\n",
    "ice_donuk=['yalnÄ±z','keÅŸke','piÅŸman','aÄŸla','gÃ¶zyaÅŸÄ±','utanÃ§','hayÄ±r','peki','belki','bilgilendirici','ciddi']\n",
    "\n",
    "gercekci=['mÃ¼mkÃ¼n','net','olamaz','olur','oldu','olacak','tamam']\n",
    "sezgisel=['belki','muhtemelen','acaba','ihtimal','his','dÃ¼ÅŸ','rÃ¼ya','sevgi','sevmek','sezgi','seviyorum','hayranÄ±m',\n",
    "         'gerÃ§eklik']\n",
    "\n",
    "dusunen=['dÃ¼ÅŸÃ¼nce','dÃ¼ÅŸÃ¼nÃ¼yorum','aslÄ±nda','mantÄ±klÄ±','doÄŸru','yanlÄ±ÅŸ','tespit','olmalÄ±','tahmin','anlamlÄ±','manalÄ±','ÅŸÃ¼pheli',\n",
    "         'ÅŸÃ¼pheci','Ã§Ã¼nkÃ¼']\n",
    "hassas=['kÄ±rÄ±k','buruk','hÃ¼zÃ¼n','kÄ±rgÄ±n','aÄŸla','yeterince','teÅŸekkÃ¼r','hassas','kÄ±rÄ±lgan']\n",
    "\n",
    "sorgulayan=['neden','ne','nerede','niÃ§in''ara','zaman','saat','ilk','son','net']\n",
    "algÄ±lari_acik=['Ã¶ÄŸrendim','Ã¶ÄŸretici','bence',]\n",
    "\n",
    "#DÄ±ÅŸa dÃ¶nÃ¼k / GerÃ§ekÃ§i / DÃ¼ÅŸÃ¼nen / Sorgulayan\n",
    "Kisilik_1=[]\n",
    "\n",
    "#Ä°Ã§e dÃ¶nÃ¼k / GerÃ§ekÃ§i / DÃ¼ÅŸÃ¼nen / Sorgulayan\n",
    "Kisilik_2=[]\n",
    "\n",
    "#DÄ±ÅŸa dÃ¶nÃ¼k / GerÃ§ekÃ§i / Hassas / Sorgulayan\n",
    "Kisilik_3=[]\n",
    "\n",
    "#Ä°Ã§e dÃ¶nÃ¼k / GerÃ§ekÃ§i / Hassas / Sorgulayan\n",
    "Kisilik_4=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_disa_donuk = df_all['Tweets'].str.contains('|'.join(disa_donuk))\n",
    "total_ice_donuk = df_all['Tweets'].str.contains('|'.join(ice_donuk))\n",
    "\n",
    "total_gercekci = df_all['Tweets'].str.contains('|'.join(gercekci))\n",
    "total_sezgisel = df_all['Tweets'].str.contains('|'.join(sezgisel))\n",
    "\n",
    "total_dusunen = df_all['Tweets'].str.contains('|'.join(dusunen))\n",
    "total_hassas = df_all['Tweets'].str.contains('|'.join(hassas))\n",
    "                                           \n",
    "total_sorgulayan = df_all['Tweets'].str.contains('|'.join(sorgulayan))\n",
    "total_algÄ±lari_acik = df_all['Tweets'].str.contains('|'.join(algÄ±lari_acik)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  disa_donuk ice_donuk gercekci sezgisel dusunen hassas sorgulayan  \\\n",
      "0      False     False    False    False   False  False      False   \n",
      "1      False     False    False    False   False  False      False   \n",
      "2      False     False    False    False   False  False       True   \n",
      "3       True     False    False    False   False  False      False   \n",
      "4      False     False    False    False   False  False      False   \n",
      "5      False     False    False    False   False  False      False   \n",
      "6      False     False    False    False   False  False      False   \n",
      "7      False     False    False    False   False  False      False   \n",
      "8      False     False    False    False   False  False      False   \n",
      "9      False     False    False    False   False  False      False   \n",
      "\n",
      "  algÄ±lari_acik  \n",
      "0         False  \n",
      "1         False  \n",
      "2         False  \n",
      "3         False  \n",
      "4         False  \n",
      "5         False  \n",
      "6         False  \n",
      "7         False  \n",
      "8         False  \n",
      "9         False  \n"
     ]
    }
   ],
   "source": [
    "df_total=pd.concat([total_disa_donuk,total_ice_donuk,total_gercekci,total_sezgisel,total_dusunen,total_hassas,total_sorgulayan,total_algÄ±lari_acik],ignore_index=True, axis=1)\n",
    "df_total.columns = [ 'disa_donuk','ice_donuk','gercekci','sezgisel','dusunen','hassas','sorgulayan','algÄ±lari_acik']                                         \n",
    "\n",
    "print(df_total.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DÄ±ÅŸa DÃ¶nÃ¼k ! \n"
     ]
    }
   ],
   "source": [
    "DÄ±s=df_total['disa_donuk'][df_total['disa_donuk']==True].count().sum()\n",
    "Ic=df_total['ice_donuk'][df_total['ice_donuk']==True].count().sum()\n",
    "\n",
    "if(DÄ±s>Ic):\n",
    "    print(\"DÄ±ÅŸa DÃ¶nÃ¼k ! \")\n",
    "elif(DÄ±s==Ic):\n",
    "    print(\"Dengeli.\")\n",
    "else:\n",
    "    print(\"Ä°Ã§e DÃ¶nÃ¼k...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GerÃ§ekÃ§i ! \n"
     ]
    }
   ],
   "source": [
    "G=df_total['gercekci'][df_total['gercekci']==True].count().sum()\n",
    "S=df_total['sezgisel'][df_total['sezgisel']==True].count().sum()\n",
    "\n",
    "if(G>S):\n",
    "    print(\"GerÃ§ekÃ§i ! \")\n",
    "elif(G==S):\n",
    "    print(\"Dengeli.\")\n",
    "else:\n",
    "    print(\"Sezgisel...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dengeli.\n"
     ]
    }
   ],
   "source": [
    "D=df_total['dusunen'][df_total['dusunen']==True].count().sum()\n",
    "H=df_total['hassas'][df_total['hassas']==True].count().sum()\n",
    "\n",
    "if(D>H):\n",
    "    print(\"DÃ¼ÅŸÃ¼nen..\")\n",
    "elif(D==H):\n",
    "    print(\"Dengeli.\")\n",
    "else:\n",
    "    print(\"Hassas...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorgulayan..\n"
     ]
    }
   ],
   "source": [
    "Sor=df_total['sorgulayan'][df_total['sorgulayan']==True].count().sum()\n",
    "Alg=df_total['algÄ±lari_acik'][df_total['algÄ±lari_acik']==True].count().sum()\n",
    "\n",
    "if(Sor>Alg):\n",
    "    print(\"Sorgulayan..\")\n",
    "elif(Sor==Alg):\n",
    "    print(\"Dengeli.\")\n",
    "else:\n",
    "    print(\"AlgÄ±larÄ± AÃ§Ä±k...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
